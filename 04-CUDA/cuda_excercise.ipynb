{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Setting up cuda in colab\n",
        "!pip install nvcc4jupyter\n",
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "id": "ZTuhTnw3gqxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CUDA Programming - Excercise\n",
        "In this excercise, you will be doing two excercises.\n",
        "1. Find Weighted Sum of an array\n",
        "2. Linear Regression in CUDA"
      ],
      "metadata": {
        "id": "eCjlS4ycUtiR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weighted sum of an array using CUDA\n",
        "Consider an array $X=[3,4,5,6,7,8,9]$ and a filter with $c=[0.1,0.6,0.1]$ then the c-weighted sum of $X$ is given as $Y=[0, 3.2, 4, 4.8, 5.6, 6.4, 0]$"
      ],
      "metadata": {
        "id": "lk2DBQUkb36H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4GvWCe6Ulx5"
      },
      "outputs": [],
      "source": [
        "# Sample python code\n",
        "import numpy as np\n",
        "def apply_filter(X,c):\n",
        "  N = np.size(X)\n",
        "  m = np.size(c)\n",
        "  Y = np.zeros(N)\n",
        "  for i in range(1,N-1):\n",
        "    Y[i] = c[0]*X[i-1] + c[1]*X[i] + c[2]*X[i+1]\n",
        "  return Y\n",
        "\n",
        "X = np.array([3,4,5,6,7,8,9])\n",
        "C = np.array([0.1,0.6,0.1])\n",
        "print(apply_filter(X,C))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "#include <cuda.h>\n",
        "\n",
        "#define N 1024\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__constant__ float filter[3] = {0.2,0.6,0.2};\n",
        "\n",
        "__global__ void apply_filter(float *x, float *y){\n",
        "    // Your code goes here\n",
        "\n",
        "    // till here\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    float X_hs[N], *X_dev;\n",
        "    float Y_hs[N], *Y_dev;\n",
        "\n",
        "    // Initialise vector\n",
        "    for(int i=0;i<N;i++){\n",
        "        X_hs[i] = i * 1.0;\n",
        "        Y_hs[i] = 0.0;\n",
        "    }\n",
        "    // Allocate memory in GPU (device)\n",
        "\n",
        "    // Transfer data to GPU\n",
        "\n",
        "    // Launch Kernel\n",
        "     apply_filter<<<32,32>>>(X_dev, Y_dev);\n",
        "\n",
        "    // Transfer data back to CPU\n",
        "\n",
        "\n",
        "    for(int i=0;i<10;i++){\n",
        "        cout << Y_hs[i] << endl;\n",
        "    }\n",
        "    // Free memory in GPU\n",
        "    cudaFree(X_hs);\n",
        "    cudaFree(Y_hs);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "eqib3QW4UtIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear regression in CUDA"
      ],
      "metadata": {
        "id": "H_vd-b8qqdS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include<iostream>\n",
        "#include<cuda.h>\n",
        "#include<cmath>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__global__ void perform_gradient_update(float *x, float w, float b, float lr){\n",
        "    // w - Weight, b - bias, x - vector, lr - learning rate\n",
        "  // Your code goes here\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "  float *x_hs,*x_dev;\n",
        "  bool isConverged = false;\n",
        "  x_dev = new float[N];\n",
        "  for(int i=0; i<N; i++)\n",
        "    x_dev[i] = i + cos(6.0*i/float(N));\n",
        "  while(!isConverged){\n",
        "  // Your code goes here\n",
        "      perform_gradient_update<<<1,N>>>();\n",
        "      cudaThreadSynchronize();\n",
        "\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "dgOHS0bAhQIG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}