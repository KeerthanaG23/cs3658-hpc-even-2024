{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j94r04NrwaL5"
      },
      "outputs": [],
      "source": [
        "# Setting up cuda in colab\n",
        "!pip install nvcc4jupyter\n",
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Caution!!\n",
        "\n",
        "A warp is a set of threads that perform instructions in lockstep. If not programmed correctly would lead to thread divergence."
      ],
      "metadata": {
        "id": "Kv__gTSKwfLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cpvec.cu\n",
        "#include <iostream>\n",
        "#include <cuda.h>\n",
        "\n",
        "#define N 8192\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__global__ void copy_vector(float *x, float *y){\n",
        "        int id = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "        y[id] = x[id];\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    float X_hs[N], *X_dev;\n",
        "    float Y_hs[N], *Y_dev;\n",
        "\n",
        "    // Initialise vector\n",
        "    for(int i=0;i<N;i++){\n",
        "        X_hs[i] = i * 1.0;\n",
        "        Y_hs[i] = 0.0;\n",
        "    }\n",
        "    // Allocate memory in GPU (device)\n",
        "    cudaMalloc(&X_dev, N * sizeof(float));\n",
        "    cudaMalloc(&Y_dev, N * sizeof(float));\n",
        "\n",
        "    // Transfer data to GPU\n",
        "    cudaMemcpy(X_dev, X_hs, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(Y_dev, Y_hs, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch Kernel\n",
        "\n",
        "     copy_vector<<<32,256>>>(X_dev, Y_dev);\n",
        "\n",
        "    // Transfer data back to CPU\n",
        "    cudaMemcpy(Y_hs, Y_dev, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cudaFree(X_hs);\n",
        "    cudaFree(Y_hs);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "gPFqtB5xwxDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o cpvec cpvec.cu"
      ],
      "metadata": {
        "id": "3elzY_V-xrfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./cpvec"
      ],
      "metadata": {
        "id": "WSoWp0TUx1FY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile man-vec.cu\n",
        "#include <iostream>\n",
        "#include <cuda.h>\n",
        "\n",
        "#define N 65536\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__global__ void manipulate_vector_v1(float *x, float *y){\n",
        "        int id = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "        if (id%4 == 0)\n",
        "          y[id] = x[id];\n",
        "        else{\n",
        "          if (id%4 == 1)\n",
        "            y[id] = x[id]+1;\n",
        "          else{\n",
        "            if (id%4 == 2)\n",
        "              y[id] = x[id]+2;\n",
        "            else\n",
        "              y[id] = x[id]+3;\n",
        "          }\n",
        "        }\n",
        "}\n",
        "\n",
        "__global__ void manipulate_vector_v2(float *x, float *y){\n",
        "        int id = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "        y[id] = x[id] + (id%4);\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    float X_hs[N], *X_dev;\n",
        "    float Y_hs[N], *Y_dev;\n",
        "\n",
        "    // Initialise vector\n",
        "    for(int i=0;i<N;i++){\n",
        "        X_hs[i] = i * 1.0;\n",
        "        Y_hs[i] = 0.0;\n",
        "    }\n",
        "    // Allocate memory in GPU (device)\n",
        "    cudaMalloc(&X_dev, N * sizeof(float));\n",
        "    cudaMalloc(&Y_dev, N * sizeof(float));\n",
        "\n",
        "    // Transfer data to GPU\n",
        "    cudaMemcpy(X_dev, X_hs, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(Y_dev, Y_hs, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch Kernel\n",
        "\n",
        "     manipulate_vector_v1<<<256,256>>>(X_dev, Y_dev);\n",
        "     manipulate_vector_v2<<<256,256>>>(X_dev, Y_dev);\n",
        "\n",
        "    // Transfer data back to CPU\n",
        "    cudaMemcpy(Y_hs, Y_dev, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cudaFree(X_hs);\n",
        "    cudaFree(Y_hs);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "jQRO93ULx8gC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o mvec man-vec.cu\n",
        "!nvprof ./mvec"
      ],
      "metadata": {
        "id": "rnhq9_c0zjCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Memory"
      ],
      "metadata": {
        "id": "J7hHwoz95tg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile trans-mat.cu\n",
        "#include <iostream>\n",
        "#include <cuda.h>\n",
        "\n",
        "#define N 65536\n",
        "const int TILE_DIM = 32;\n",
        "const int BLOCK_ROWS = 8;\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__global__ void transpose_v1(float *odata, const float *idata)\n",
        "{\n",
        "  int x = blockIdx.x * TILE_DIM + threadIdx.x;\n",
        "  int y = blockIdx.y * TILE_DIM + threadIdx.y;\n",
        "  int width = gridDim.x * TILE_DIM;\n",
        "\n",
        "  for (int j = 0; j < TILE_DIM; j+= BLOCK_ROWS)\n",
        "    odata[x*width + (y+j)] = idata[(y+j)*width + x];\n",
        "}\n",
        "\n",
        "__global__ void transpose_v2(float *odata, const float *idata)\n",
        "{\n",
        "  __shared__ float tile[TILE_DIM][TILE_DIM];\n",
        "\n",
        "  int x = blockIdx.x * TILE_DIM + threadIdx.x;\n",
        "  int y = blockIdx.y * TILE_DIM + threadIdx.y;\n",
        "  int width = gridDim.x * TILE_DIM;\n",
        "\n",
        "  for (int j = 0; j < TILE_DIM; j += BLOCK_ROWS)\n",
        "     tile[threadIdx.y+j][threadIdx.x] = idata[(y+j)*width + x];\n",
        "\n",
        "  __syncthreads();\n",
        "\n",
        "  x = blockIdx.y * TILE_DIM + threadIdx.x;  // transpose block offset\n",
        "  y = blockIdx.x * TILE_DIM + threadIdx.y;\n",
        "\n",
        "  for (int j = 0; j < TILE_DIM; j += BLOCK_ROWS)\n",
        "     odata[(y+j)*width + x] = tile[threadIdx.x][threadIdx.y + j];\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  const int nx = 1024;\n",
        "  const int ny = 1024;\n",
        "  const int mem_size = nx*ny*sizeof(float);\n",
        "\n",
        "  dim3 dimGrid(nx/TILE_DIM, ny/TILE_DIM, 1);\n",
        "  dim3 dimBlock(TILE_DIM, BLOCK_ROWS, 1);\n",
        "\n",
        "  float *h_idata = (float*)malloc(mem_size);\n",
        "  float *h_cdata = (float*)malloc(mem_size);\n",
        "  float *h_tdata = (float*)malloc(mem_size);\n",
        "\n",
        "  float *d_idata, *d_cdata, *d_tdata;\n",
        "  cudaMalloc(&d_idata, mem_size);\n",
        "  cudaMalloc(&d_cdata, mem_size);\n",
        "  cudaMalloc(&d_tdata, mem_size);\n",
        "\n",
        "\n",
        "\n",
        "  // Sample matrix\n",
        "  for (int j = 0; j < ny; j++)\n",
        "    for (int i = 0; i < nx; i++)\n",
        "      h_idata[j*nx + i] = j*nx + i;\n",
        "\n",
        "  cudaMemcpy(d_idata, h_idata, mem_size, cudaMemcpyHostToDevice);\n",
        "  transpose_v1<<<dimGrid, dimBlock>>>(d_tdata, d_idata);\n",
        "  cudaMemcpy(h_tdata, d_tdata, mem_size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  cudaMemcpy(d_idata, h_idata, mem_size, cudaMemcpyHostToDevice);\n",
        "  transpose_v2<<<dimGrid, dimBlock>>>(d_tdata, d_idata);\n",
        "  cudaMemcpy(h_tdata, d_tdata, mem_size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "aM8jn0GRzplC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o tmat trans-mat.cu\n",
        "!nvprof ./tmat"
      ],
      "metadata": {
        "id": "9ov4JHMWAAbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u3wKC0TmAGLk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}